<!DOCTYPE html>
<html>
	<head>
		<meta charset="utf-8" />
		<title>Xuan Wang's Space</title>
		<script src="js/jquery-3.6.0.min.js" type="text/javascript" charset="utf-8"></script>
		<script src="js/jquery-color.js" type="text/javascript" charset="utf-8"></script>

		<!-- <script type="text/javascript" src="https://zzr6.com/wp-content/themes/Ality/js/djtx.js"></script> -->
		<link rel="stylesheet" type="text/css" href="css/header.css" />
		<link rel="stylesheet" type="text/css" href="css/foot.css" />
		<!-- <link rel="stylesheet" type="text/css" href="css/box.css" /> -->
		<link rel="stylesheet" type="text/css" href="css/bootstrap.css" />
		<link rel="icon" href="./img/icon.png" />


		<script src="js/HeadChange.js" type="text/javascript" charset="utf-8"></script>
		<!-- <script src="js/index_show.js" type="text/javascript" charset="utf-8"></script> -->
		<!-- <link rel="stylesheet" type="text/css" href="css/middleDivide.css"/> -->

		<style type="text/css">
			* {
				margin: 0;
				padding: 0;
			}

			.ball {
				position: absolute;
				border-radius: 100%;
				opacity: 0.7;
			}

			body {
				font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, Arial, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";
				width: 100%;
				height: 100%;

				/* overflow: hidden; */
				font-size: 14px;
				color: #000000;

			}
		</style>

		<!-- <script type="text/javascript">
			// è‡ªåŠ¨è·å–æ—¥æœŸ
			var day = new Date().getDate();
			var year = new Date().getFullYear();
			var month = new Date().getMonth() + 1;
			if (month < 10) {
				month = '0' + month
			}
			var y_m = year + '-' + month
			// console.log(y_m);
			$(function() {
				$('.folkDay').text(day);
				$('.folkY-M').text(y_m);
			})
		</script> -->
	</head>

	<body>
		<script type="text/javascript" src="js/buffermove1.js"></script>
		<!-- <canvas class="fireworks" style="position:fixed;left:0;top:0;z-index:99999999;pointer-events:none;</canvas> -->
		<!-- å¤´éƒ¨ -->
		<div class="header">
			<div class="headerContent">
				<div class="headerlogo">
					<a href="index.html">Xuan Wang's Space</a>
					<!-- Xuan Wangçš„ä¸»é¡µ -->
					<!-- <img src="img/Newlogo.png"> -->
				</div>
				<div class="userbar">
					<ul>
						<li class="userbar-li-active"><a href="index.html">About</a></li>
						<li class="userbar-li"><a href="others.html">Others</a></li>
						<li class="userbar-li"><a href="projetcs.html">Projects</a></li>
						<li class="userbar-li"><a href="publications.html">Publications</a></li>

					</ul>
				</div>
			</div>
		</div>
		<div class="boderline"></div>

		<div class="introduction_box">
			<div class="introduction_content">
				<div class="introduction_TitleBox">
					<!-- <h1 class="news_momentTitleCN">ç‹ç’‡</h1> -->
					<div class="introduction_TitleCN">ç‹ç’‡</div>
					<div class="introduction_TitleEN">Xuan Wang</div>
				</div>
				<div class="introduction_text">
					<p>Xuan Wang was born in Weihai, Shandong, China in 1991. She received the B.S. and Ph.D. degrees
						from Traffic Information Engineering & Control, Changâ€™an University, China, in 2013 and 2018,
						respectively. She is currently an associate professor of the School of Computer Science and
						Control Engineering in Yantai University. Her research interests include <b>image processing,
							machine
							learning and pattern recognition.</b></p>
					<br>
					<p>
						ç‹ç’‡ï¼ŒçƒŸå°å¤§å­¦å‰¯æ•™æˆï¼ŒIEEE Senior Member, åšå£«æ¯•ä¸šäºé•¿å®‰å¤§å­¦ä¿¡æ¯å·¥ç¨‹å­¦é™¢äº¤é€šä¿¡æ¯å·¥ç¨‹åŠæ§åˆ¶ä¸“ä¸šã€‚
						è¿‘å¹´æ¥ä¸»æŒçœéƒ¨çº§è¯¾é¢˜1é¡¹ï¼Œå‚ä¸å¤šé¡¹å›½å®¶è¯¾é¢˜ï¼Œä¸»æŒå¤šé¡¹æ¨ªå‘è¯¾é¢˜ã€‚
						åœ¨IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS, PATTERN RECOGNITIONï¼ŒSUSTAINABLE CITIES AND SOCIETYï¼Œ REMOTE SENSING,SAFETY SCIENCE ç­‰å›½é™…æœŸåˆŠå‘è¡¨å­¦æœ¯è®ºæ–‡20ä½™ç¯‡ï¼Œ
						æˆæƒå‘æ˜ä¸“åˆ©10ä½™é¡¹ï¼Œå®ç”¨æ–°å‹ä¸“åˆ©9é¡¹ï¼Œè½¯ä»¶è‘—ä½œæƒ20ä½™é¡¹ã€‚
						é¦–ä½æŒ‡å¯¼å­¦ç”Ÿè·â€œæœ‰äººæ¯â€ç¬¬ä¹å±Šå±±ä¸œçœç‰©è”ç½‘åˆ›é€ åŠ›å¤§èµ›çœçº§äºŒç­‰å¥–ï¼Œè·ç¬¬åå…­å±ŠiCANå¤§å­¦ç”Ÿåˆ›æ–°åˆ›ä¸šå¤§èµ›å±±ä¸œèµ›åŒºäºŒç­‰å¥–ï¼Œè·ä¸­å›½å¤§å­¦ç”Ÿè®¡ç®—æœºè®¾è®¡å¤§èµ›çœçº§äºŒç­‰å¥–ã€‚
						æ‹…ä»»Information Sciencesã€ IEEE Internet of Things Magazine ã€ IEEE Transactions on Consumer Electronicsç­‰æœŸåˆŠçš„å®¡ç¨¿äººã€‚
						ä¸»è¦ç ”ç©¶æ–¹å‘ï¼š<b>è®¡ç®—æœºè§†è§‰ï¼Œæ¨¡å¼è¯†åˆ«ï¼Œè¶…åˆ†è¾¨é‡å»ºç­‰é¢†åŸŸ</b>
					</p>
					<br>
					<div class="little_Title">åŸºæœ¬ä¿¡æ¯</div>
					<div class="devide"></div>
					<!-- <h2>åŸºæœ¬ä¿¡æ¯</h2> -->
					<p class="basci_p"><b>å·¥ä½œå•ä½ï¼š</b> çƒŸå°å¤§å­¦è®¡ç®—æœºä¸æ§åˆ¶å·¥ç¨‹å­¦é™¢</p>
					<p class="basci_p"><b>ç”µå­é‚®ç®±ï¼š</b> xuanwang_91@126.com, xuanwang91@ytu.edu.cn</p>
					<p class="basci_p"><b>åŠå…¬åœ°å€ï¼š</b> å±±ä¸œçœçƒŸå°å¸‚è±å±±åŒºæ¸…æ³‰è·¯30å·çƒŸå°å¤§å­¦ç§‘æŠ€é¦†4405</p>
					<p class="basci_p"><b>å®éªŒå®¤ï¼š</b> çƒŸå°å¤§å­¦ç§‘æŠ€é¦†6408æ™ºæ…§äº¤é€šå®éªŒå®¤</p>

				</div>
				<div class="introduction_img">
					<img src="img/xuan.jpg" / width="200" align="right">
				</div>
			</div>
		</div>

		<div class="news">
			<div class="news_TitleBox">
				<div class="little_Title">æ–°é—»</div>
			</div>
			<ul>
				<li>ğŸˆğŸˆğŸˆ<font color="#dd0000">æ¬¢è¿å„ä½åŒå­¦åŠ å…¥è¯¾é¢˜ç»„æ”»è¯»ç¡•å£«ç ”ç©¶ç”Ÿï¼åŒæ—¶æ¬¢è¿æœ¬ç§‘ç”Ÿè¿›å…¥å®éªŒå®¤ï¼</font>
				</li>

				<li> <b><em>6/9/2025</em></b> ğŸˆ<font color="#dd0000">æ­å–œæ¢å¹¿æµ©è·ä¼˜ç§€æœ¬ç§‘æ¯•ä¸šè®ºæ–‡ï¼</font>
				<li><b><em>6/9/2025</em></b> ğŸˆæ­å–œæ¯•å­£å¹³åŒå­¦çš„è®ºæ–‡<a
						href="https://ieeexplore.ieee.org/abstract/document/10995224">â€œFreq-3DLane: 3D Lane Detection From Monocular Images
					via Frequency-Aware Feature Fusionâ€</a>è¢«IEEE Transactions on Intelligent Transportation Systemså½•ç”¨ï¼</li>
				
				<li><b><em>6/9/2025</em></b> ğŸˆæ­å–œå¼ å³»è±ªåŒå­¦çš„è®ºæ–‡<a
						href="files/Deep learning for hyperspectral image classification A comprehensive review and future predictions.pdf">â€œDeep learning for
					hyperspectral image classification A comprehensive
					review and future predictionsâ€</a>è¢«Information Fusion(ä¸­ç§‘é™¢SCIä¸€åŒº) å½•ç”¨ï¼</li>
				
				<li> <b><em>2/21/2025</em></b> ğŸˆ<font color="#dd0000">æ­å–œæå‡¯å¼ºåŒå­¦ã€å­™å…†æ°åŒå­¦è·å¾—å›½å®¶å¥–å­¦é‡‘ï¼</font>
				<li><b><em>1/23/2025</em></b> ğŸˆæ­å–œæ¯•å­£å¹³åŒå­¦çš„è®ºæ–‡<a
						href="files/2025-Lane_Detection_for_Autonomous_Driving_Comprehensive_Reviews_Current_Challenges_and_Future_Predictions.pdf">â€œLane Detection 
					        for Autonomous Driving: Comprehensive Reviews, Current Challenges, and Future 
					        Predictionsâ€</a>è¢«IEEE Transactions on Intelligent Transportation Systems(ä¸­ç§‘é™¢SCIä¸€åŒºTop) å½•ç”¨ï¼</li>
				
				<li><b><em>1/6/2025</em></b> ğŸˆæ­å–œé‡‘å¸Œæ™ºåŒå­¦ï¼ˆæœ¬ç§‘ç”Ÿï¼‰çš„è®ºæ–‡<a
						href="files/2025-Deep_Learning-Based_Methods_for_Road_Extraction_From_Remote_Sensing_Images_A_vision_survey_and_future_directions.pdf">â€œDeep 
					        Learning-Based Methods for Road Extraction From Remote Sensing Images: A vision, survey, and future 
					        directionsâ€</a>è¢«IEEE Geoscience and Remote Sensing Magazine(ä¸­ç§‘é™¢SCIä¸€åŒº) å½•ç”¨ï¼</li>
				
				<li><b><em>12/9/2024</em></b> ğŸˆæ­å–œå­™ä¸½ä¿ŠåŒå­¦çš„è®ºæ–‡<a
						href="files/2025-DRGAN_A_Detail_Recovery-Based_Model_for_Optical_Remote_Sensing_Images_Super-Resolution.pdf">â€œDRGAN: 
					        A Detail Recovery-Based Model for Optical Remote Sensing Images 
					        Super-Resolutionâ€</a>è¢«IEEE Transactions on Geoscience and Remote Sensing (ä¸­ç§‘é™¢SCIä¸€åŒº) å½•ç”¨ï¼</li>
				
				<li><b><em>11/13/2024</em></b> ğŸˆæ­å–œå­™ä¸½ä¿ŠåŒå­¦çš„è®ºæ–‡<a
						href="https://www.sciencedirect.com/science/article/abs/pii/S1077314224002637">â€œEfficient
						degradation representation learning network for remote sensing image
						super-resolutionâ€</a>è¢«Computer Vision and Image Understanding (ä¸­ç§‘é™¢SCIä¸‰åŒº) å½•ç”¨ï¼</li>

				<li><b><em>1/9/2024</em></b> ğŸˆæ­å–œå­™å…†æ°åŒå­¦çš„è®ºæ–‡<a
						href="https://www.sciencedirect.com/science/article/abs/pii/S1566253524000253">â€œDeep Learning
						and
						Multi-modal Fusion for Real-time
						Multi-object Tracking: Algorithms, Challenges, Datasets, and Comparative Studyâ€</a>è¢«Information
					Fusion
					(ä¸­ç§‘é™¢SCIä¸€åŒº) å½•ç”¨ï¼</li>

				<li><b><em>12/7/2023</em></b> ğŸˆæ­å–œæ¯•å­£å¹³åŒå­¦çš„è®ºæ–‡<a
						href="https://www.sciencedirect.com/science/article/pii/S2542660523003529">â€œDesign and
						Implementation of Intelligent Monitoring System for Agricultural Environment in
						IoTâ€</a>è¢«Internet of
					Things
					(ä¸­ç§‘é™¢SCIä¸‰åŒº) å½•ç”¨ï¼</li>


				<li><b><em>11/11/2023</em></b> ğŸˆæ­å–œç‹å‚²ç„¶åŒå­¦çš„è®ºæ–‡<a
						href="https://www.mdpi.com/1999-4907/14/11/2261">â€œApplication
						of the YOLOv6 Combining CBAM and CIoU in Forest Fire and Smoke Detectionâ€</a>è¢«Forests (ä¸­ç§‘é™¢SCIäºŒåŒº)
					å½•ç”¨ï¼
				</li>

				<li> <b><em>11/2/2023</em></b> ğŸˆ<font color="#dd0000">æ­å–œæå‡¯å¼ºåŒå­¦è·å¾—2023å¹´åº¦ä¼˜ç§€ç ”ç©¶ç”Ÿçš„ç§°å·ï¼</font>

				<li><b><em>10/19/2023</em></b> ğŸˆæ­å–œå­™ä¸½ä¿ŠåŒå­¦çš„è®ºæ–‡<a href="https://www.mdpi.com/2072-4292/15/20/5062">â€œA Review
						of
						GAN-based Super-
						Resolution Reconstruction for Remote
						Sensing lmagesâ€</a>è¢«Remote Sensing (ä¸­ç§‘é™¢SCIäºŒåŒº) å½•ç”¨ï¼</li>


				<li><b><em>9/14/2023</em></b> ğŸˆæ­å–œæå‡¯å¼ºåŒå­¦çš„è®ºæ–‡<a
						href="files/2023-Multi-Sensor_Fusion_Technology_for_3D_Object_Detection_in_Autonomous_Driving_A_Review.pdf">â€œMulti-Sensor
						Fusion Technology for 3D Object Detection
						in Autonomous Driving: A Reviewâ€</a>è¢«IEEE Transactions on Intelligent Transportation Systems
					(ä¸­ç§‘é™¢SCIä¸€åŒº) å½•ç”¨ï¼</li>

				<li><b><em>8/15/2023</em></b> ğŸˆæ­å–œå­™å…†æ°åŒå­¦çš„è®ºæ–‡<a
						href="files/2023-A comprehensive review of pedestrian re-identification based on deep learning.pdf">â€œA
						Comprehensive Review of Pedestrian Re-identification
						Based on Deep Learningâ€</a>è¢«Complex & Intelligent Systems (ä¸­ç§‘é™¢SCIäºŒåŒº) å½•ç”¨ï¼</li>

				<li><b><em>6/25/2023</em></b> ğŸˆæ­å–œç‹å‚²ç„¶åŒå­¦çš„è®ºæ–‡<a href="https://www.mdpi.com/2072-4292/15/13/3265">â€œSmall
						Object
						Detection Based on Deep Learning for Remote Sensing:
						A
						Comprehensive Reviewâ€</a>è¢«Remote Sensing (ä¸­ç§‘é™¢SCIäºŒåŒº) å½•ç”¨ï¼</li>
			</ul>
		</div>

		<div class="students">
			<div class="little_Title">æŒ‡å¯¼å­¦ç”Ÿ</div>

			<table id="customers">
				<tr>
					<th>å§“å</th>
					<th>å¹´çº§</th>
					<th>ç ”ç©¶æ–¹å‘</th>
					<th>æˆæœ</th>
				</tr>
				
				<tr>
					<td>å•å¤</td>
					<td>2024</td>
					<td>3Dç›®æ ‡æ£€æµ‹</td>
					<td>
						
					</td>
				</tr>
				<tr>
					<td>å¼ å³»è±ª</td>
					<td>2024</td>
					<td>é«˜å…‰è°±å›¾åƒåˆ†ç±»</td>
					<td>
						<!-- <a href="https://www.sciencedirect.com/science/article/abs/pii/S1566253525003586">Deep learning for
						hyperspectral image classification: A comprehensive review and future predictions</a> -->
						Information Fusion(ä¸­ç§‘é™¢SCIä¸€åŒº)ä¸€ç¯‡
					</td>
				</tr>
				<tr>
					<td>é‚±å¸…åº·</td>
					<td>2024</td>
					<td>åŒ»å­¦å›¾åƒåˆ†å‰²</td>
					<td>
						
					</td>
				</tr>
				<tr>
					<td>è‘£éª¥æ‰¬</td>
					<td>2024</td>
					<td>é¥æ„Ÿå°ç›®æ ‡æ£€æµ‹</td>
					<td>
						
					</td>
				</tr>

				<tr>
					<td>ç‹å‚²ç„¶</td>
					<td>2023</td>
					<td>é¥æ„Ÿå°ç›®æ ‡æ£€æµ‹ </td>
					<td>
						<!-- <a href="https://www.mdpi.com/2072-4292/15/13/3265">Small
							Object
							Detection Based on Deep Learning for Remote Sensing:
							A
							Comprehensive Review</a>
						<br>
						<a href="https://www.mdpi.com/1999-4907/14/11/2261">Application
							of the YOLOv6 Combining CBAM and CIoU in Forest Fire and Smoke Detection</a> -->
						Remote Sensing(SCI 2åŒº)ä¸€ç¯‡ï¼ŒForests(SCI 2åŒº)ä¸€ç¯‡
					</td>
				</tr>

				<tr>
					<td>å¼ ä¸€å…µ</td>
					<td>2023</td>
					<td>ç›®æ ‡è·Ÿè¸ª</td>
					<td>

					</td>
				</tr>

				<tr>
					<td>å­™ä¸½ä¿Š</td>
					<td>2023</td>
					<td>é¥æ„Ÿå›¾åƒè¶…åˆ†è¾¨é‡å»º</td>
					<td>
						<!-- <a href="https://www.mdpi.com/2072-4292/15/20/5062">A Review
							of
							GAN-based Super-
							Resolution Reconstruction for Remote
							Sensing lmages</a> -->
						IEEE Transactions on Geoscience and Remote Sensing (ä¸­ç§‘é™¢SCIä¸€åŒº)ä¸€ç¯‡ï¼ŒRemote Sensing(SCI 2åŒº)ä¸€ç¯‡ï¼ŒComputer Vision and Image Understanding(SCI 3åŒº)ä¸€ç¯‡
					</td>
				</tr>

				<tr>
					<td>æ¯•å­£å¹³</td>
					<td>2023</td>
					<td>3Dè½¦é“çº¿æ£€æµ‹ </td>
					<td>
						<!-- <a href="https://www.sciencedirect.com/science/article/pii/S2542660523003529">Design and
							Implementation of Intelligent Monitoring System for Agricultural Environment in
							IoT</a> -->
						IEEE Transactions on Intelligent Transportation Systems(ä¸­ç§‘é™¢SCIä¸€åŒºTop)ä¸€ç¯‡ï¼ŒInternet of Things(SCI 3åŒº)ä¸€ç¯‡
					</td>
				</tr>

				<tr>
					<td>æå‡¯å¼º</td>
					<td>2022</td>
					<td>3Dç›®æ ‡æ£€æµ‹</td>
					<td>
						IEEE Transactions on Intelligent Transportation Systems(SCI 1åŒº)ä¸€ç¯‡
						<!-- <a href="https://ieeexplore.ieee.org/document/10265760">Multi-Sensor Fusion Technology
							for
							3D Object
							Detection in Autonomous Driving: A Review</a> -->
					</td>
				</tr>
				<tr>
					<td>å­™å…†æ°</td>
					<td>2022</td>
					<td>ç›®æ ‡è·Ÿè¸ª</td>
					<td>

						<!-- <a href="https://www.sciencedirect.com/science/article/abs/pii/S1566253524000253">Deep
							Learning and
							Multi-modal Fusion for Real-time
							Multi-object Tracking: Algorithms, Challenges, Datasets, and Comparative Study</a>
						<br />
						<a
							href="files/2023-A comprehensive review of pedestrian re-identification based on deep learning.pdf">A
							Comprehensive Review of Pedestrian Re-identification
							Based on Deep Learning</a></li> -->
						Complex & Intelligent Systems(SCI 2åŒº)ä¸€ç¯‡ï¼ŒInformation Fusion(SCI 1åŒº)ä¸€ç¯‡
					</td>
				</tr>

				<tr>
					<td>éƒ­å¥</td>
					<td>2021</td>
					<td>äº¤é€šç›®æ ‡æ£€æµ‹</td>
					<td>
						<!-- <a href="https://www.mdpi.com/1424-8220/22/18/6930">Real-time
							and Efficient Multi-scale Traffic Sign Detection
							Method
							for
							Driverless Cars</a> -->
						Sensors(SCI 3åŒº)ä¸€ç¯‡
					</td>
				</tr>

				<tr>
					<td>è¡£é™è•¾</td>
					<td>2021</td>
					<td>è¶…åˆ†è¾¨ç‡å›¾åƒé‡å»º</td>
					<td>
						<!-- <ul>
							<li>
								<a href="https://www.mdpi.com/2072-4292/14/21/5423">A Review of
									Image Super-resolution and Remote Sensing
									Applications</a>
							</li>
						</ul> -->
						<!-- <a href="https://www.mdpi.com/2072-4292/14/21/5423">A Review of
							Image Super-resolution and Remote Sensing
							Applications</a> -->
						Remote Sensing(SCI 2åŒº)ä¸€ç¯‡
					</td>
				</tr>

			</table>


			<!-- <ol>

				<li>ç‹å‚²ç„¶ï¼Œ2023çº§ï¼Œç ”ç©¶æ–¹å‘ï¼šé¥æ„Ÿå°ç›®æ ‡æ£€æµ‹ (å‘è¡¨äºŒç¯‡SCIäºŒåŒºè®ºæ–‡)</li>
				<li>å¼ ä¸€å…µï¼Œ2023çº§ï¼Œç ”ç©¶æ–¹å‘ï¼šç›®æ ‡è·Ÿè¸ª</li>
				<li>å­™ä¸½ä¿Šï¼Œ2023çº§ï¼Œç ”ç©¶æ–¹å‘ï¼šé¥æ„Ÿå›¾åƒè¶…åˆ†è¾¨é‡å»º (å‘è¡¨ä¸€ç¯‡SCIäºŒåŒºè®ºæ–‡)</li>
				<li>æ¯•å­£å¹³ï¼Œ2023çº§ï¼Œç ”ç©¶æ–¹å‘ï¼š3Dè½¦é“çº¿æ£€æµ‹ (å½•ç”¨ä¸€ç¯‡SCIä¸‰åŒºè®ºæ–‡)</li>

				<li>æå‡¯å¼ºï¼Œ2022çº§ï¼Œç ”ç©¶æ–¹å‘ï¼š3Dç›®æ ‡æ£€æµ‹ (å½•ç”¨ä¸€ç¯‡SCIä¸€åŒºè®ºæ–‡)</li>
				<li>å­™å…†æ°ï¼Œ2022çº§ï¼Œç ”ç©¶æ–¹å‘ï¼šè¡Œäººé‡è¯†åˆ« (å½•ç”¨ä¸€ç¯‡SCIä¸€åŒºè®ºæ–‡ã€ä¸€ç¯‡SCIäºŒåŒºè®ºæ–‡)</li>

				<li>éƒ­å¥ï¼Œ2021çº§ï¼Œç ”ç©¶æ–¹å‘ï¼šäº¤é€šç›®æ ‡æ£€æµ‹ (å‘è¡¨ä¸€ç¯‡SCIä¸‰åŒºè®ºæ–‡)</li>
				<li>è¡£é™è•¾ï¼Œ2021çº§ï¼Œç ”ç©¶æ–¹å‘ï¼šè¶…åˆ†è¾¨å›¾åƒé‡å»º (å‘è¡¨ä¸€ç¯‡SCIäºŒåŒºè®ºæ–‡)</li>

			</ol> -->
		</div>

		<div class="paper">
			<div class="little_Title">ä»£è¡¨è®ºæ–‡</div>
			<ol>

				<li><u>Xuan Wang</u>, Xizhi Jin, Zhe Dai, Yuxuan Wu and Abdellah Chehri.
					<a href="https://ieeexplore.ieee.org/document/10826577">Deep Learning-Based 
                                                 Methods for Road Extraction From Remote Sensing Images</a>
					<b><i>IEEE Geoscience and Remote Sensing Magazine</i></b>
				</li>

				<li>Yongchao Song , Lijun Sun , Jiping Bi , Siwen Quan , and <u> Xuan Wang</u>
					<a href="https://ieeexplore.ieee.org/document/10781453">DRGAN: A Detail 
						Recovery-Based Model for Optical Remote Sensing Images Super-Resolution</a>
					<b><i>IEEE Transactions on Geoscience and Remote Sensing</i></b>
				</li>
				
				<li><u>Xuan Wang</u>, Kaiqiang Li and Abdellah Chehri.
					<a href="https://ieeexplore.ieee.org/document/10265760">Multi-Sensor Fusion Technology for 3D Object
						Detection in Autonomous Driving: A Review.</a>
					<b><i>IEEE Transactions on Intelligent Transportation Systems</i></b>
				</li>

				<li><u>Xuan Wang</u>, Zhaojie Sun, Abdellah Chehri, Gwanggil Jeon, Yongchao Song.
					<a href="https://www.sciencedirect.com/science/article/abs/pii/S1566253524000253">Deep Learning and
						Multi-modal Fusion for Real-time
						Multi-object Tracking: Algorithms, Challenges, Datasets, and Comparative Study.</a>
					<b><i>Information Fusion</i></b>
				</li>

				<li>Yongchao Song , Junhao Zhang , Zhaowei Liu , Yang Xu , Siwen Quan , Lijun Sun , Jiping Bi , <u> Xuan Wang </u>.
					<a href="https://www.sciencedirect.com/science/article/abs/pii/S1566253525003586">Deep learning
						for hyperspectral image classification:
						A comprehensive review and future predictions</a>
					<b><i>Information Fusion</i></b>
				</li>

			   <!-- <li><u>Xuan Wang</u>, Jinglei Yi, Jian Guo, Yongchao Song, Jun Lyu, Jindong Xu, Weiqing Yan, Jindong
					Zhao,
					Qing Cai, and Haigen Min.
					<a href="https://www.mdpi.com/2072-4292/14/21/5423">A Review of Image Super-Resolution Approaches
						Based on Deep Learning and Applications in Remote Sensing.</a>
					<b><i>Remote Sensing 2022</i></b>
				</li>-->

				<li><u> Xuan Wang</u>, Lijun Sun, Jinglei Yi,Yongchao Song, Qiang Zheng, Abdellah Chehri
					<a href="https://www.sciencedirect.com/science/article/abs/pii/S1077314224002637">Efficient 
						degradation representation learning network for remote sensing image super-resolution</a>
					<b><i>Computer Vision and Image Understanding</i></b>
				</li>
				
			     <li>Yongchao Song , Jiping Bi , Lijun Sun , Zhaowei Liu , Yahong Jiang , <u> Xuan Wang</u>.
					<a href="https://ieeexplore.ieee.org/abstract/document/10995224">Freq-3DLane: 3D Lane Detection
						From Monocular Images via Frequency-Aware Feature Fusion</a>
					<b><i>IEEE Transactions on Intelligent Transportation Systems</i></b>
				 </li>

				<!-- <li>Yongchao Song, Tao Huang, Xin Fu, Yahong Jiang, Jindong Xu, Jindong Zhao, Weiqing Yan, and <u>Xuan
						Wang</u>#
					<a href="https://www.mdpi.com/2220-9964/12/3/132">A Novel Lane Line Detection Algorithm for
						Driverless Geographic Information Perception Using Mixed-Attention Mechanism ResNet and Row
						Anchor Classification.</a>
					<b><i>ISPRS International Journal of Geo-Information 2023</i></b>
				</li>

				<li>Mingwei Lei, Yongchao Song, Jindong Zhao, <u>Xuan Wang</u> , Jun Lyu, Jindong Xu, and Weiqing Yan.
					<a href="https://www.mdpi.com/1424-8220/22/22/8693">End-to-End Network for Pedestrian Detection,
						Tracking and Re-Identification in Real-Time Surveillance System.</a>
					<b><i>Sensors 2022</i></b>
				</li>

				<li><u>Xuan Wang</u> , Jinglei Yi, Jian Guo, Yongchao Song, Jun Lyu, Jindong Xu, Weiqing Yan, Jindong
					Zhao,
					Qing Cai, and Haigen Min.
					<a href="https://www.mdpi.com/2072-4292/14/21/5423">A Review of Image Super-Resolution Approaches
						Based on Deep Learning and Applications in Remote Sensing.</a>
					<b><i>Remote Sensing 2022</i></b>
				</li>

				<li>Qianpeng Chong, Jindong Xu, Fei Jia, Zhaowei Liu, Weiqing Yan, <u>Xuan Wang</u> , and Yongchao Song.
					<a href="https://www.tandfonline.com/doi/abs/10.1080/01431161.2022.2135413">A multiscale fuzzy
						dual-domain attention network
						for urban remote sensing image segmentation.</a>
					<b><i>International Journal of Remote Sensing 2022</i></b>
				</li>

				<li><u>Xuan Wang</u> , Jian Guo, Jinglei Yi, Yongchao Song, Jindong Xu, Weiqing Yan, and Xin Fu.
					<a href="https://www.mdpi.com/1424-8220/22/18/6930">Real-Time and Efficient Multi-Scale Traffic Sign
						Detection Method for Driverless Cars.</a>
					<b><i>Sensors Sep 2022</i></b>
				</li>



				<li><u>Xuan Wang</u> , Jindong Xu, Yongchao Song, Qiang Zheng, Jun Lv, Weiqing Yan, Qing Cai, and Zhe
					Dai.
					<a href="https://www.sciencedirect.com/science/article/abs/pii/S0925753521002630">Vehicle behavior
						analysis using reconstructed 3D
						parameters for road safety.</a>
					<b><i>Safety science 2021</i></b>
				</li>

				<li>Zhe Dai, Huansheng Song, Haoxiang Liang, Feifan Wu, <u>Xuan Wang</u> , Jinming Jia, and Yong Fang.
					<a href="https://link.springer.com/article/10.1007/s12652-020-02052-5">Traffic parameter estimation
						and control system
						based on machine vision.</a>
					<b><i>Journal of Ambient Intelligence and Humanized Computing 2020</i></b>
				</li>

				<li><u>Xuan Wang</u> , and Zhe Dai.
					<a href="Vhttps://link.springer.com/article/10.1007/s12652-019-01581-y">Vision-based vehicle
						behavior monitoring method
						using a novel clustering algorithm.</a>
					<b><i>Journal of Ambient Intelligence and Humanized Computing 2019</i></b>
				</li>

				<li><u>Xuan Wang</u> , Huansheng Song, Qi Guan, Hua Cui, Zhaoyang Zhang, and Haiying Liu.
					<a href="https://www.sciencedirect.com/science/article/abs/pii/S2210670717310089">Vehicle motion
						segmentation using rigid motion constraints in traffic video.</a>
					<b><i>Sustainable Cities and Society 2018</i></b>
				</li>

				<li>Huansheng Song, <u>Xuan Wang</u> , Cui Hua, Weixing Wang, Qi Guan, and Zhaoyang Zhang.
					<a href="https://link.springer.com/article/10.1007/s00500-017-2831-0">Vehicle trajectory clustering
						based on 3D information via a coarse-to-fine strategy.</a>
					<b><i>Soft Computing 2018</i></b>
				</li> -->
			</ol>
		</div>
		<div class="foot">
			<b>æ›´æ–°æ—¶é—´ï¼š2025/6/9</b>
		</div>
	</body>
	<style>
		ul {
			/* text-indent: 1em; /* è®¾ç½®æ‚¬æŒ‚ç¼©è¿› */
			left: auto;
			padding-left: 2em;
			/* è¡¥å¿æ‚¬æŒ‚ç¼©è¿›çš„å·¦ä¾§ç©ºç™½ */
		}

		.box {
			width: 980px;
			margin: auto;
		}

		.devide {
			height: 5px
		}

		.basci_p {
			line-height: 1.8em;
		}

		.paper {
			width: 960px;
			margin: auto;
			margin-top: 20px;
		}

		.paper li {
			margin-bottom: 5px;
		}

		.paper ol {
			font-size: 16px;
			margin-left: 15px;
			line-height: 1.8em;
			font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, Arial, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";
		}

		.paper a {
			color: #0366d6;
			text-decoration: none;
		}

		.paper a:hover {
			color: #0366d6;
			text-decoration: underline;
		}

		.news a {
			color: #0366d6;
			text-decoration: none;
		}

		.news a:hover {
			color: #0366d6;
			text-decoration: underline;
		}


		.students {
			width: 960px;
			margin: auto;
			margin-top: 20px;
		}

		.students ol {
			font-size: 16px;
			margin-left: 15px;
			line-height: 1.8em;
			font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, Arial, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";

		}


		.little_Title {
			text-align: left;
			color: #000000;
			font-size: 25px;
			height: 40px;
			margin-bottom: 10px;
			line-height: 40px;
			border-bottom: 1px #eeeeee solid;
			/* float: left; */
			font-weight: 900;
		}

		/* @media screen and (max-width: 600px) {
		  
		  news {background-color: #0366d6;}
		} */


		.news {
			width: 960px;
			margin: auto;
			margin-top: 160px;
		}

		.news li {
			font-size: 16px;
			margin-bottom: 5px;
			line-height: 1.5em;
			font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, Arial, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";
		}

		.news_TitleBox {
			width: 100%;
			height: 40px;
			padding-bottom: 5px;
			margin-bottom: 10px;
			/* border-bottom: 1px #eeeeee solid; */
		}

		.news_content {}

		.news_time {
			font-style: italic;
		}




		.introduction_box {
			width: 960px;
			height: 350px;
			margin: auto;
		}

		.introduction_content {
			margin-top: 20px;
			/* width: 1080px; */
			/* border: 1px solid pink; */
			margin-left: auto;
			margin-right: auto;
		}

		.introduction_TitleBox {
			width: 100%;
			height: 40px;
			padding-bottom: 5px;
			border-bottom: 1px #eeeeee solid;
		}

		.introduction_TitleCN {
			text-align: center;
			color: #000000;
			font-size: 30px;
			height: 40px;
			line-height: 40px;
			float: left;
			font-weight: 900;
		}

		.introduction_TitleEN {
			color: #999999;
			text-align: center;
			font-size: 25px;
			margin-left: 15px;
			height: 40px;
			float: left;
			line-height: 40px;
			/* float: bottom; */
		}

		.introduction_text {
			width: 75%;
			/* background-color: aqua; */
			margin-top: 10px;
			float: left;
			height: 200px;
		}

		.introduction_text p {
			font-size: 16px;
		}

		.introduction_img {
			margin-top: 10px;
			width: 25%;
			height: 350px;
			float: right;
			/* background-color: antiquewhite; */
		}

		#customers {
			font-size: 16px;
			/* font-family: Arial, Helvetica, sans-serif; */
			border-collapse: collapse;
			width: 100%;

			/* table-layout: auto */
		}

		#customers a {
			font-size: 16px;
			/* font-family: Arial, Helvetica, sans-serif; */
			border-collapse: collapse;
			width: 100%;
			color: #0366d6;
			line-height: 1.5em;
			/* table-layout: auto */
		}

		#customers ul {
			text-align: -2em;
			padding-left: 20px;
			left: 20px;

			/* table-layout: auto */
		}


		#customers td,
		#customers th {
			border: 1px solid #ddd;
			padding-left: 10px;
			padding-right: 10px;
			padding-top: 5px;
			padding-bottom: 5px;
			/* padding: 10px; */

		}

		#customers tr:nth-child(even) {
			background-color: #f5f5f5;
		}

		#customers th {
			padding-top: 12px;
			padding-bottom: 12px;
			text-align: left;
			/* background-color: rgba(3, 102, 214,0.2); */

			/* color: white; */

		}

		/* å‰ä¸‰åˆ—ä¸æ¢è¡Œ */
		th:nth-child(-n+3),
		td:nth-child(-n+3) {
			white-space: nowrap;
		}

		/* æœ€åä¸€åˆ—è‡ªåŠ¨æ¢è¡Œ */
		th:nth-child(4),
		td:nth-child(4) {
			text-align: justify;
			white-space: normal;
		}
	</style>
</html>
